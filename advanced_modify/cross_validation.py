from sklearn.model_selection import cross_validate, KFold
import pandas as pd
import numpy as np

def enhanced_cross_validate(model, features=None, target_col = None, cv=5, verbose=True, return_df=False):
    """
    æ”¯æŒ MAEã€MSEã€RÂ² çš„äº¤å‰éªŒè¯å‡½æ•°
    """

    scoring = {
        'MAE': 'neg_mean_absolute_error',
        'MSE': 'neg_mean_squared_error',
        'R2': 'r2'
    }

    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)

    scores = cross_validate(model, features, target_col, cv=kfold, scoring=scoring, return_train_score=False)

    # è½¬ä¸º DataFrame æ–¹ä¾¿åå¤„ç†
    df_scores = pd.DataFrame(scores)
    
    if verbose:
        print(f"ğŸ“Š {cv}-æŠ˜äº¤å‰éªŒè¯ç»“æœ:")
        for metric in ['MAE', 'MSE', 'R2']:
            test_col = f'test_{metric}'
            mean = df_scores[test_col].mean()
            std = df_scores[test_col].std()
            if metric != 'R2':  # MAE, MSE æ˜¯è´Ÿçš„
                mean, std = -mean, std
            print(f"ğŸ”¹ {metric:<4}: {mean:.4f} Â± {std:.4f}")

    if return_df:
        return df_scores
    else:
        return {metric: df_scores[f'test_{metric}'] for metric in scoring}

##æŒ‡å®šè¯„ä¼°æ ‡å‡†ï¼ˆå›å½’æ¨¡å‹æœ€å¸¸è§å¦‚ MAEã€RMSEã€RÂ²ï¼‰
##verbose, å¦‚æœä¸º Trueï¼Œå°±ä¼šæ‰“å°æ¯ä¸€æŠ˜çš„å¾—åˆ†å’Œå‡å€¼Â±æ ‡å‡†å·®